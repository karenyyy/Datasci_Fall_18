
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}
	\usepackage{float}
    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Programming 3}
    \author{Jiarong Ye}
    
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \subsection*{Import Packages}\label{import-packages}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{from} \PY{n+nn}{mpl\PYZus{}toolkits}\PY{n+nn}{.}\PY{n+nn}{mplot3d} \PY{k}{import} \PY{n}{Axes3D}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k}{import} \PY{n}{KMeans}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{datasets}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{normalize}
         \PY{k+kn}{from} \PY{n+nn}{copy} \PY{k}{import} \PY{n}{deepcopy}
         
         \PY{n}{iris} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{load\PYZus{}iris}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}X = iris.data}
         \PY{n}{X} \PY{o}{=} \PY{n}{norm}\PY{p}{(}\PY{n}{iris}\PY{o}{.}\PY{n}{data}\PY{p}{)}
         \PY{n}{y} \PY{o}{=} \PY{n}{iris}\PY{o}{.}\PY{n}{target}
\end{Verbatim}

    \subsection*{KMeans.py}\label{kmeans.py}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}143}]:} \PY{c+c1}{\PYZsh{} kmeans.py}
          
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{f1\PYZus{}score}\PY{p}{,} \PY{n}{normalized\PYZus{}mutual\PYZus{}info\PYZus{}score}
          
          \PY{n}{THRESHOLD} \PY{o}{=} \PY{l+m+mf}{1e\PYZhy{}5}
          
          \PY{k}{def} \PY{n+nf}{norm}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Function you should not touch}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{max\PYZus{}val} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{n}{x} \PY{o}{=} \PY{n}{x} \PY{o}{/} \PY{n}{max\PYZus{}val}
              \PY{k}{return} \PY{n}{x}
          
          
          \PY{k}{def} \PY{n+nf}{rand\PYZus{}center}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{k}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Function you need to write}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Select \PYZdq{}k\PYZdq{} random points from \PYZdq{}data\PYZdq{} as the initial centroids.}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{n\PYZus{}samples}\PY{p}{,} \PY{n}{n\PYZus{}features} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{shape}\PY{p}{(}\PY{n}{data}\PY{p}{)}
              \PY{n}{centroids} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{k}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{p}{)}\PY{p}{)}
              \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{k}\PY{p}{)}\PY{p}{:}
                  \PY{n}{centroid} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}samples}\PY{p}{)}\PY{p}{)}\PY{p}{]}
                  \PY{n}{centroids}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{centroid}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZgt{}\PYZgt{}\PYZgt{} initial centroids}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{centroids}\PY{p}{)}
              \PY{k}{return} \PY{n}{centroids}
          
          
          \PY{k}{def} \PY{n+nf}{converged}\PY{p}{(}\PY{n}{centroids1}\PY{p}{,} \PY{n}{centroids2}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Function you need to write}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} check whether centroids1==centroids}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} add proper code to handle infinite loop if it never converges}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{diff} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{centroids1} \PY{o}{\PYZhy{}} \PY{n}{centroids2}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{equal}\PY{p}{(}\PY{n}{centroids1}\PY{p}{,} \PY{n}{centroids2}\PY{p}{)}\PY{o}{.}\PY{n}{all}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{k+kc}{True}
              \PY{k}{elif} \PY{n}{diff} \PY{o}{\PYZlt{}} \PY{n}{THRESHOLD}\PY{p}{:}
                  \PY{k}{return} \PY{k+kc}{True}
              \PY{k}{else}\PY{p}{:}
                  \PY{k}{return} \PY{k+kc}{False}
          
          
          \PY{k}{def} \PY{n+nf}{euclidean\PYZus{}dist}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{)}\PY{p}{:}
              \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{x1} \PY{o}{\PYZhy{}} \PY{n}{x2}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          
          
          \PY{k}{def} \PY{n+nf}{closest\PYZus{}centroid}\PY{p}{(}\PY{n}{val}\PY{p}{,} \PY{n}{centroids}\PY{p}{)}\PY{p}{:}
              \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{argmin}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{val} \PY{o}{\PYZhy{}} \PY{n}{centroids}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          
          
          \PY{k}{def} \PY{n+nf}{update\PYZus{}centroids}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{centroids}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Function you need to write}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Assign each data point to its nearest centroid based on the Euclidean distance}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Update the cluster centroid to the mean of all the points assigned to that cluster}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{n\PYZus{}samples} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{shape}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
              \PY{n}{n\PYZus{}features} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{shape}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
              \PY{n}{clusters} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{p}{]} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{k}\PY{p}{)}\PY{p}{]}
              \PY{n}{labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{n\PYZus{}samples}\PY{p}{)}\PY{p}{)}
          
              \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
                  \PY{n}{val\PYZus{}label} \PY{o}{=} \PY{n}{closest\PYZus{}centroid}\PY{p}{(}\PY{n}{val}\PY{p}{,} \PY{n}{centroids}\PY{p}{)}
                  \PY{n}{clusters}\PY{p}{[}\PY{n}{val\PYZus{}label}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{val}\PY{p}{)}
                  \PY{n}{labels}\PY{p}{[}\PY{n}{idx}\PY{p}{]} \PY{o}{=} \PY{n}{val\PYZus{}label}
              \PY{n}{centroids} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{k}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{p}{)}\PY{p}{)}
              \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{n}{cluster\PYZus{}val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{clusters}\PY{p}{)}\PY{p}{:}
                  \PY{n}{centroid} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{cluster\PYZus{}val}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
                  \PY{n}{centroids}\PY{p}{[}\PY{n}{idx}\PY{p}{]} \PY{o}{=} \PY{n}{centroid}
              \PY{k}{return} \PY{n}{centroids}\PY{p}{,} \PY{n}{labels}
          
          
          \PY{k}{def} \PY{n+nf}{kmeans}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{k}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Function you should not touch}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{c+c1}{\PYZsh{} step 1:}
              \PY{n}{centroids} \PY{o}{=} \PY{n}{rand\PYZus{}center}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{k}\PY{p}{)}
              \PY{n}{converge} \PY{o}{=} \PY{k+kc}{False}
              \PY{n}{iteration} \PY{o}{=} \PY{l+m+mi}{0}
              \PY{k}{while} \PY{o+ow}{not} \PY{n}{converge}\PY{p}{:}
                  \PY{n}{old\PYZus{}centroids} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{n}{centroids}\PY{p}{)}
                  \PY{c+c1}{\PYZsh{} step 2 \PYZam{} 3}
                  \PY{n}{centroids}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{n}{update\PYZus{}centroids}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{old\PYZus{}centroids}\PY{p}{)}
                  \PY{c+c1}{\PYZsh{} step 4}
                  \PY{n}{converge} \PY{o}{=} \PY{n}{converged}\PY{p}{(}\PY{n}{old\PYZus{}centroids}\PY{p}{,} \PY{n}{centroids}\PY{p}{)}
                  \PY{n}{iteration} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of iterations to converge: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{iteration}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZgt{}\PYZgt{}\PYZgt{} final centroids}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{centroids}\PY{p}{)}
              \PY{k}{return} \PY{n}{centroids}\PY{p}{,} \PY{n}{label}
          
          
          \PY{k}{def} \PY{n+nf}{evaluation}\PY{p}{(}\PY{n}{predict}\PY{p}{,} \PY{n}{ground\PYZus{}truth}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} use F1 and NMI in scikit\PYZhy{}learn for evaluation}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{f1} \PY{o}{=} \PY{n}{f1\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{o}{=}\PY{n}{ground\PYZus{}truth}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{o}{=}\PY{n}{predict}\PY{p}{,} \PY{n}{average}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{weighted}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{nmi} \PY{o}{=} \PY{n}{normalized\PYZus{}mutual\PYZus{}info\PYZus{}score}\PY{p}{(}\PY{n}{labels\PYZus{}true}\PY{o}{=}\PY{n}{ground\PYZus{}truth}\PY{p}{,} \PY{n}{labels\PYZus{}pred}\PY{o}{=}\PY{n}{predict}\PY{p}{)}
              \PY{k}{return} \PY{n}{f1}\PY{p}{,} \PY{n}{nmi}
          
          
          \PY{k}{def} \PY{n+nf}{gini}\PY{p}{(}\PY{n}{predict}\PY{p}{,} \PY{n}{ground\PYZus{}truth}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} use the ground truth to do majority vote to assign a flower type for each cluster}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} accordingly calculate the probability of missclassifiction and correct classification}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} finally, calculate gini using the calculated probabilities}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{labels} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{ground\PYZus{}truth}\PY{p}{)}
              \PY{n}{num\PYZus{}labels} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{labels}\PY{p}{)}
              \PY{n}{cluster\PYZus{}p}\PY{p}{,} \PY{n}{cluster\PYZus{}g} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{0} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}labels}\PY{p}{)}\PY{p}{]}\PY{p}{,} 
              			\PY{p}{[}\PY{l+m+mi}{0} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}labels}\PY{p}{)}\PY{p}{]}
              \PY{n}{gini\PYZus{}index} \PY{o}{=} \PY{l+m+mi}{0}
              \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{labels}\PY{p}{:}
                  \PY{n}{cluster\PYZus{}p}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{cluster\PYZus{}g}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{predict}\PY{p}{[}\PY{n}{predict}\PY{o}{==}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                  			 \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{ground\PYZus{}truth}\PY{p}{[}\PY{n}{ground\PYZus{}truth}\PY{o}{==}\PY{n}{i}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
                  \PY{k}{if} \PY{n}{cluster\PYZus{}p}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{\PYZlt{}}\PY{n}{cluster\PYZus{}g}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{:}
                      \PY{n}{correct\PYZus{}prob} \PY{o}{=} \PY{n}{cluster\PYZus{}p}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{o}{/}\PY{n}{cluster\PYZus{}g}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                      \PY{n}{incorrect\PYZus{}prob} \PY{o}{=} \PY{p}{(}\PY{n}{cluster\PYZus{}g}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{cluster\PYZus{}p}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{o}{/}\PY{n}{cluster\PYZus{}g}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                      \PY{n}{gini\PYZus{}index} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{correct\PYZus{}prob}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{incorrect\PYZus{}prob}\PY{p}{)}
              \PY{n}{gini\PYZus{}index} \PY{o}{/}\PY{o}{=} \PY{n}{num\PYZus{}labels}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gini Index :}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{gini\PYZus{}index}\PY{p}{)}
              \PY{k}{return} \PY{n}{gini\PYZus{}index}
          
          
          \PY{k}{def} \PY{n+nf}{SSE}\PY{p}{(}\PY{n}{centroids}\PY{p}{,} \PY{n}{data}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} Calculate the sum of squared errors for each cluster}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{clusters} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{p}{]} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n}{centroids}\PY{p}{]}
              \PY{n}{num\PYZus{}centroids} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{centroids}\PY{p}{)}
              \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{n}{data}\PY{p}{:}
                  \PY{n}{clusters}\PY{p}{[}\PY{n}{closest\PYZus{}centroid}\PY{p}{(}\PY{n}{val}\PY{p}{,} \PY{n}{centroids}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{val}\PY{p}{)}
              \PY{n}{sse\PYZus{}each\PYZus{}cluster} \PY{o}{=} \PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{clusters}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{centroids}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}centroids}\PY{p}{)}\PY{p}{]}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SSE\PYZus{}each\PYZus{}cluster: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sse\PYZus{}each\PYZus{}cluster}\PY{p}{)}
              \PY{k}{return} \PY{n}{sse\PYZus{}each\PYZus{}cluster}
          
          
          \PY{k}{def} \PY{n+nf}{plot\PYZus{}result}\PY{p}{(}\PY{n}{model}\PY{p}{)}\PY{p}{:}
              \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
              \PY{n}{ax} \PY{o}{=} \PY{n}{Axes3D}\PY{p}{(}\PY{n}{fig}\PY{p}{,} \PY{n}{rect}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{o}{.}\PY{l+m+mi}{95}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{elev}\PY{o}{=}\PY{l+m+mi}{48}\PY{p}{,} \PY{n}{azim}\PY{o}{=}\PY{l+m+mi}{134}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                         \PY{n}{c}\PY{o}{=}\PY{n}{label}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{)}\PY{p}{,} \PY{n}{edgecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{w\PYZus{}xaxis}\PY{o}{.}\PY{n}{set\PYZus{}ticklabels}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{w\PYZus{}yaxis}\PY{o}{.}\PY{n}{set\PYZus{}ticklabels}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{w\PYZus{}zaxis}\PY{o}{.}\PY{n}{set\PYZus{}ticklabels}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Petal width}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sepal length}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}zlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Petal length}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{3 clusters \PYZhy{} }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{model}\PY{p}{)}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{dist} \PY{o}{=} \PY{l+m+mi}{12}
          
              \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

\newpage

    \subsection*{Q1}\label{q1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run your own k-Means multiple times (at least 10 times) to find the
  best three clustering based on SSE (sum of squared errors) and compare
  it with the result obtained from k-Means in scikit-learn for
  comparison. Show both clustering results using matplotlib.
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}145}]:} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
              \PY{n}{centroids}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{n}{kmeans}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
              \PY{n}{evaluation}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
              \PY{n}{gini}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
              \PY{n}{SSE}\PY{p}{(}\PY{n}{centroids}\PY{p}{,} \PY{n}{X}\PY{p}{)}
              \PY{n}{plot\PYZus{}result}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ours}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.72151899 0.59090909 0.50724638 0.4       ]
 [0.69620253 0.54545455 0.53623188 0.4       ]
 [0.84810127 0.68181818 0.75362319 0.92      ]]
number of iterations to converge:  4
>>> final centroids
[[0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]
 [0.84045359 0.68560606 0.80676329 0.8225    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [0.5860971086851517, 1.0302179676457113, 1.2157725785900486]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.5443038  0.68181818 0.15942029 0.04      ]
 [0.82278481 0.72727273 0.73913043 0.8       ]
 [0.79746835 0.77272727 0.8115942  0.96      ]]
number of iterations to converge:  7
>>> final centroids
[[0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]
 [0.84045359 0.68560606 0.80676329 0.8225    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [0.5860971086851517, 1.0302179676457113, 1.2157725785900486]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.84810127 0.56818182 0.84057971 0.72      ]
 [0.64556962 0.75       0.24637681 0.2       ]
 [0.78481013 0.77272727 0.7826087  0.92      ]]
number of iterations to converge:  7
>>> final centroids
[[0.74853944 0.62237762 0.62263099 0.53      ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.84045359 0.68560606 0.80676329 0.8225    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.0302179676457113, 0.5860971086851517, 1.2157725785900486]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.62025316 0.70454545 0.2173913  0.04      ]
 [0.72151899 0.65909091 0.60869565 0.52      ]
 [0.60759494 0.68181818 0.20289855 0.04      ]]
number of iterations to converge:  7
>>> final centroids
[[0.66229656 0.8336039  0.21532091 0.11428571]
 [0.79265823 0.65272727 0.71101449 0.6704    ]
 [0.5972382  0.70454545 0.20816864 0.07636364]]
Gini Index : 0.3285333333333333
SSE\_each\_cluster:  [0.21307645052258836, 5.538389212891668, 0.09732480213098582]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.86075949 0.72727273 0.85507246 0.92      ]
 [0.82278481 0.68181818 0.75362319 0.8       ]
 [0.87341772 0.70454545 0.73913043 0.92      ]]
number of iterations to converge:  10
>>> final centroids
[[0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.2157725785900486, 0.5860971086851517, 1.0302179676457113]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.91139241 0.68181818 0.84057971 0.64      ]
 [0.72151899 1.         0.2173913  0.16      ]
 [0.70886076 0.65909091 0.52173913 0.52      ]]
number of iterations to converge:  4
>>> final centroids
[[0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.2157725785900486, 0.5860971086851517, 1.0302179676457113]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.84810127 0.68181818 0.75362319 0.92      ]
 [0.63291139 0.77272727 0.2173913  0.08      ]
 [0.83544304 0.68181818 0.63768116 0.56      ]]
number of iterations to converge:  4
>>> final centroids
[[0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.2157725785900486, 0.5860971086851517, 1.0302179676457113]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.72151899 0.65909091 0.60869565 0.52      ]
 [0.84810127 0.70454545 0.8115942  0.96      ]
 [0.6835443  0.77272727 0.24637681 0.08      ]]
number of iterations to converge:  4
>>> final centroids
[[0.74853944 0.62237762 0.62263099 0.53      ]
 [0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.0302179676457113, 1.2157725785900486, 0.5860971086851517]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.69620253 0.52272727 0.57971014 0.52      ]
 [0.79746835 0.52272727 0.63768116 0.52      ]
 [0.83544304 0.68181818 0.63768116 0.56      ]]
number of iterations to converge:  5
>>> final centroids
[[0.63367089 0.77681818 0.21217391 0.0976    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]
 [0.84045359 0.68560606 0.80676329 0.8225    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [0.5860971086851517, 1.0302179676457113, 1.2157725785900486]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.73417722 0.61363636 0.73913043 0.76      ]
 [0.86075949 0.72727273 0.85507246 0.92      ]
 [0.60759494 0.77272727 0.27536232 0.08      ]]
number of iterations to converge:  7
>>> final centroids
[[0.74853944 0.62237762 0.62263099 0.53      ]
 [0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.0302179676457113, 1.2157725785900486, 0.5860971086851517]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_5_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    
    
     \subsubsection*{sklearn}\label{sklearn}
    
    \begin{Verbatim}[commandchars=\\\{\}]
    \PY{n}{est} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
    \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
    \PY{n}{ax} \PY{o}{=} \PY{n}{Axes3D}\PY{p}{(}\PY{n}{fig}\PY{p}{,} \PY{n}{rect}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{o}{.}\PY{l+m+mi}{95}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{elev}\PY{o}{=}\PY{l+m+mi}{48}\PY{p}{,} \PY{n}{azim}\PY{o}{=}\PY{l+m+mi}{134}\PY{p}{)}
    \PY{n}{est}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{)}
    \PY{n}{labels} \PY{o}{=} \PY{n}{est}\PY{o}{.}\PY{n}{labels\PYZus{}}
    
    \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
    \PY{n}{evaluation}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{y}\PY{p}{)}
    \PY{n}{gini}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{y}\PY{p}{)}
    \PY{n}{plot\PYZus{}result}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sklearn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \end{Verbatim}
    
    \begin{Verbatim}[commandchars=\\\{\}]
    Gini Index : 0.025600000000000008
    
    \end{Verbatim}
    
    \begin{center}
    	\adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_12_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    
    
    
    \subsection*{Q2}\label{q2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Use the results obtained in (1) to explain why it's important to
  choose proper initial centroids.
\end{enumerate}

    From the result of question 1 we can observe in one case that when we
choose the initial centroids as :

\begin{verbatim}
[[0.62025316 0.70454545 0.2173913  0.04      ]
 [0.72151899 0.65909091 0.60869565 0.52      ]
 [0.60759494 0.68181818 0.20289855 0.04      ]]
\end{verbatim}

the evaluation parameters we get are:

\begin{itemize}
\tightlist
\item
  Gini Index : 0.3285333333333333
\item
  SSE\_each\_cluster:

  \begin{itemize}
  \tightlist
  \item[*]
    {[}0.21307645052258836, 5.538389212891668, 0.09732480213098582{]}
  \end{itemize}
\end{itemize}

There is no feasible way to guarantee finding the optimal solution
because the clustering analysis is a NP hard problem, heuristics
approaches are needed to get an outcome that's more likely to be
optimal. So there's a chance that with poorly chosen initial centroids,
the results might be suboptimal.

    \subsection*{Q3}\label{q3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Between the best clusterings you obtained via scikit-learn and your
  own k-Means implementation, which clustering is better? Please make
  comparison in terms of Impurity (Gini Index) of the clusterings. To
  compute. Gini Index for a clustering, use the ground truth (i.e.,
  flower types of data points) to do majority vote in order to assign a
  flower type for each cluster. Accordingly, calculate the probability
  of misclassification and correct classification. Finally, calculate
  Gini Index for a clustering using the calculated probabilities.
\end{enumerate}

    \subsubsection*{our Kmeans}\label{our-kmeans}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}147}]:} \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{centroids}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{n}{kmeans}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{evaluation}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{gini}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{SSE}\PY{p}{(}\PY{n}{centroids}\PY{p}{,} \PY{n}{X}\PY{p}{)}
          \PY{n}{plot\PYZus{}result}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ours}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.70886076 0.68181818 0.65217391 0.6       ]
 [0.6835443  0.68181818 0.65217391 0.6       ]
 [0.72151899 1.         0.2173913  0.16      ]]
number of iterations to converge:  6
>>> final centroids
[[0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.2157725785900486, 1.0302179676457113, 0.5860971086851517]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection*{sklearn}\label{sklearn}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}152}]:} \PY{n}{est} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
          \PY{n}{ax} \PY{o}{=} \PY{n}{Axes3D}\PY{p}{(}\PY{n}{fig}\PY{p}{,} \PY{n}{rect}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{o}{.}\PY{l+m+mi}{95}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{elev}\PY{o}{=}\PY{l+m+mi}{48}\PY{p}{,} \PY{n}{azim}\PY{o}{=}\PY{l+m+mi}{134}\PY{p}{)}
          \PY{n}{est}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{)}
          \PY{n}{labels} \PY{o}{=} \PY{n}{est}\PY{o}{.}\PY{n}{labels\PYZus{}}
          
          \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{evaluation}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{gini}\PY{p}{(}\PY{n}{labels}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{plot\PYZus{}result}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sklearn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Gini Index : 0.025600000000000008

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_12_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection*{Discussion}\label{discussion}

    Comparing the evaluation of our kmeans and the kmeans built in the
sklearn package, the Gini Index of the best case in the 10 tests run
with our kmeans is equivalent to the Gini Index calculated from sklearn.

    \subsection*{Q4}\label{q4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  In lab3.py, the data points are normalized (see line 12) by default as
  a data preprocessing step. What happens if you use the raw data (line
  11) without any data preprocessing? Between normalized and
  unnormalized datasets, which one obtains better clustering? Please
  make comparison in terms of Impurity (Gini Index) of the clusterings
  and computational cost (number of iterations to converge).
\end{enumerate}

    \subsubsection*{un-normalize}\label{un-normalize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}158}]:} \PY{n}{X} \PY{o}{=} \PY{n}{iris}\PY{o}{.}\PY{n}{data}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}161}]:} \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{centroids}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{n}{kmeans}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{evaluation}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{gini}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{SSE}\PY{p}{(}\PY{n}{centroids}\PY{p}{,} \PY{n}{X}\PY{p}{)}
          \PY{n}{plot\PYZus{}result}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ours}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[7.1 3.  5.9 2.1]
 [6.  2.9 4.5 1.5]
 [6.5 3.  5.5 1.8]]
number of iterations to converge:  8
>>> final centroids
[[6.85       3.07368421 5.74210526 2.07105263]
 [5.006      3.418      1.464      0.244     ]
 [5.9016129  2.7483871  4.39354839 1.43387097]]
Gini Index : 0.1216
SSE\_each\_cluster:  [23.87947368421052, 15.240400000000001, 39.82096774193548]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection*{normalize}\label{normalize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}162}]:} \PY{n}{X} \PY{o}{=} \PY{n}{norm}\PY{p}{(}\PY{n}{iris}\PY{o}{.}\PY{n}{data}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}169}]:} \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{centroids}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{n}{kmeans}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} this is the function you are supposed to implement in kmeans.py}
          \PY{n}{evaluation}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{gini}\PY{p}{(}\PY{n}{label}\PY{p}{,} \PY{n}{y}\PY{p}{)}
          \PY{n}{SSE}\PY{p}{(}\PY{n}{centroids}\PY{p}{,} \PY{n}{X}\PY{p}{)}
          
          \PY{n}{plot\PYZus{}result}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ours}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
>>> initial centroids
[[0.73417722 0.61363636 0.73913043 0.76      ]
 [0.83544304 0.68181818 0.63768116 0.56      ]
 [0.70886076 0.65909091 0.52173913 0.52      ]]
number of iterations to converge:  5
>>> final centroids
[[0.84045359 0.68560606 0.80676329 0.8225    ]
 [0.74853944 0.62237762 0.62263099 0.53      ]
 [0.63367089 0.77681818 0.21217391 0.0976    ]]
Gini Index : 0.025600000000000008
SSE\_each\_cluster:  [1.2157725785900486, 1.0302179676457113, 0.5860971086851517]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection*{Discussion}\label{discussion}

    From the evaluation results, we can see that the normalized dataset
obtains better clustering, reducing the Gini Index by approximately
0.096 from 0.1216 to 0.0256. And with regard to the computational cost,
the number of iterations consumed to for the algorithm trained by
unnormalized dataset to converge is 8 and the number of iterations for
the algorithm trained by normalized dataset is 5 (\emph{however by
running the test for a few times, the numbers of iterations took for
both unnormalized and normalized dataset to converge are mostly similar
and not significantly different})

    \subsection*{Q5}\label{q5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  By comparing the clusterings in (3) and (4) against the ground truth,
  explain whether Impurity is a reasonable quality measure for
  clustering?
\end{enumerate}

    \subsubsection*{ground truth
visualization}\label{ground-truth-visualization}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}170}]:} \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
          \PY{n}{ax} \PY{o}{=} \PY{n}{Axes3D}\PY{p}{(}\PY{n}{fig}\PY{p}{,} \PY{n}{rect}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{o}{.}\PY{l+m+mi}{95}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{elev}\PY{o}{=}\PY{l+m+mi}{48}\PY{p}{,} \PY{n}{azim}\PY{o}{=}\PY{l+m+mi}{134}\PY{p}{)}
          
          \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{label} \PY{o+ow}{in} \PY{p}{[}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Setosa}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,}
                              \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Versicolour}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
                              \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Virginica}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{]}\PY{p}{:}
              \PY{n}{ax}\PY{o}{.}\PY{n}{text3D}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{n}{y} \PY{o}{==} \PY{n}{label}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                        \PY{n}{X}\PY{p}{[}\PY{n}{y} \PY{o}{==} \PY{n}{label}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{,}
                        \PY{n}{X}\PY{p}{[}\PY{n}{y} \PY{o}{==} \PY{n}{label}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{name}\PY{p}{,}
                        \PY{n}{horizontalalignment}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                        \PY{n}{bbox}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{alpha}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{edgecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{facecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{w}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{choose}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{float}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{edgecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{ax}\PY{o}{.}\PY{n}{w\PYZus{}xaxis}\PY{o}{.}\PY{n}{set\PYZus{}ticklabels}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{w\PYZus{}yaxis}\PY{o}{.}\PY{n}{set\PYZus{}ticklabels}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{w\PYZus{}zaxis}\PY{o}{.}\PY{n}{set\PYZus{}ticklabels}\PY{p}{(}\PY{p}{[}\PY{p}{]}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Petal width}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sepal length}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}zlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Petal length}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ground Truth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{dist} \PY{o}{=} \PY{l+m+mi}{12}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_26_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection*{Discussion}\label{discussion}

    Impurity is a reasonable quality measure for clustering from the
clusterings we got from (3) and (4). Because:

\begin{itemize}
\tightlist
\item
  Impurity (in this case, the Gini Index) could be used as evaluation
  criteria for the algorithm to determine its optimality:

  \begin{itemize}
  \tightlist
  \item[*]
    In question 3, Gini Index is used for comparison of clusterings
    obtained between our KMeans and the one from sklearn package;
  \item[*]
    In question 4, Gini Index is used for comparison of clusterings
    obtained between KMeans models trained with normalized and
    unnormalized dataset
  \end{itemize}
\end{itemize}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
