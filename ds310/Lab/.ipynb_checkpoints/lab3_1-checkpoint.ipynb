{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "__Kernel SVM__\n",
    "\n",
    "From  sklearn  import  the  Breast  Cancer  dataset.   Draw  the  contour plots generated by fitting an SVM with the following kernels to the data (you can use sklearn’s implementation of SVM):\n",
    "\n",
    "- (a)  Linear kernel\n",
    "- (b)  Radial Basis Function (RBF) kernel\n",
    "- (c)  Polynomial kernel of degree 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load breast cancer data from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data[:, :2]\n",
    "labels = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(x, \n",
    "                 y, \n",
    "                 labels,\n",
    "                 models,\n",
    "                 row,\n",
    "                 col,\n",
    "                 figsize,\n",
    "                 cmap1,\n",
    "                 cmap2,\n",
    "                 titles,\n",
    "                 multiple=True):\n",
    "    # meshgrid\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "    fig, sub = plt.subplots(row,\n",
    "                            col, \n",
    "                            figsize=figsize)\n",
    "    try:\n",
    "        s = sub.flatten()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        s = sub\n",
    "    for model, title, ax in zip(models, titles, s):\n",
    "        Xy = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Xy = Xy.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Xy, cmap=cmap1)\n",
    "        ax.scatter(x, y, c=labels, s=50, cmap=cmap2)\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (20,6)\n",
    "models = (SVC(kernel='linear'),\n",
    "          SVC(kernel='rbf'),\n",
    "          SVC(kernel='poly', degree=5)\n",
    "         )\n",
    "models = (clf.fit(X, labels) for clf in models)\n",
    "\n",
    "TITLES = ('SVC with linear kernel',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 5) kernel')\n",
    "\n",
    "plot_contour(x=X[:, 0],\n",
    "             y=X[:, 1],\n",
    "             labels=labels,\n",
    "             models=models,\n",
    "             row=1,\n",
    "             col=3,\n",
    "             figsize=FIGSIZE,\n",
    "             cmap1=plt.cm.coolwarm,\n",
    "             cmap2=plt.cm.coolwarm,\n",
    "             titles=TITLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "__Kernel logistic regression__  \n",
    "\n",
    "In this exercise,  we're interested in using RBF kernel in  logistic  regression.   Report  the  average  area  under  curve  (AUC)  of  10-fold  cross-validation  (where  in  each  fold  you  use  20%  of  the  data  for  testing)  on  the  Breast Cancer dataset using RBF logistic regression (you can use sklearn implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "labels = cancer.target\n",
    "\n",
    "def rbf_kernel(x, mean, sd):\n",
    "    return np.exp(-1/(2*sd**2)*(x-mean)**2)\n",
    "\n",
    "\n",
    "def evaluate(X_train, X_test, y_train, y_test, fold):\n",
    "    clf = LogisticRegression(solver='lbfgs')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_pred)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    plot_roc(fpr, tpr, auc_value, fold=fold)\n",
    "\n",
    "def plot_roc(fpr, tpr, auc_value, fold=None):\n",
    "    plt.subplot(2,5,fold)\n",
    "    plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve (area = %0.3f)' % auc_value)\n",
    "    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    if fold != None:\n",
    "        plt.title('ROC plot of fold {}\\n auc = {}'.format(fold, auc_value))\n",
    "    else:\n",
    "        plt.title('ROC plot, auc = {}'.format(auc_value))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "\n",
    "def k_fold_evaluate(X, y):\n",
    "    # initialization\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall=[]\n",
    "    f1 = []\n",
    "    fold = 1\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=100, shuffle= True)\n",
    "    \n",
    "    # rbf\n",
    "    X = rbf_kernel(X, 0, 1)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(len(test_index)/(len(X)))\n",
    "        X_train, X_test, y_train, y_test = X[train_index, :], X[test_index, :], y[train_index], y[test_index]\n",
    "        evaluate(X_train, X_test, y_train, y_test, fold)\n",
    "        fold += 1\n",
    "        \n",
    "plt.figure(figsize=(25, 8))     \n",
    "k_fold_evaluate(X, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "__Soft-margin kernel SVM__\n",
    "\n",
    "Implement  soft-margin SVM with a linear kernel, optimize the objective function according to slides #119-120 of the lecture slides on ”Lectures 15-16 Maximum Margin Linear Classifiers” onthe course website.1Fit your implemented classifier to the Breast Cancer dataset anddraw the contour plot similar to question 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(w, b) = \\frac{1}{2}w^TXw + C\\sum^m_{i=1} \\max(0, 1-y_i (X_i \\cdot w + b)) $$\n",
    "\n",
    "__Derivative:__\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w} = C \\sum^m_{i=1} \\mathbb{I} (y_i (X_i \\cdot w +b)<1) \\cdot (-y_i X_i) + X_i w$$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b} = C \\sum_{i=1}^m \\mathbb{I} (y_i (X_i \\cdot w +b)<1) \\cdot (-y_i)$$\n",
    "\n",
    "__Update:__\n",
    "\n",
    "$$w \\leftarrow w - \\eta \\frac{\\partial J}{\\partial w}$$\n",
    "\n",
    "$$b \\leftarrow b - \\eta \\frac{\\partial J}{\\partial b}$$\n",
    "\n",
    "\n",
    "#### Augmented matrix $[w, b]$:\n",
    "\n",
    "$$J(w, b) = \\frac{1}{2}w^TXw + C\\sum^{m}_{i=1} \\max(0, 1-y_i (X_i \\cdot w )) $$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w} = C \\sum^{m+1}_{i=1} \\mathbb{I} (y_i (X_i \\cdot w )<1) \\cdot (-y_i X_i) + X_i w$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SoftMarginSVM:\n",
    "    def __init__(self,\n",
    "                 X,\n",
    "                 y,\n",
    "                 C=3,\n",
    "                 learning_rate=0.001,\n",
    "                 n_iter=100000):\n",
    "        # augmented matrix X = [w, b]\n",
    "        self.X = np.hstack([X, np.ones([X.shape[0],1])])\n",
    "        self.y = np.where(y==0, -1, 1) # original y is (0,1), otherwise \n",
    "        self.n_sample=self.X.shape[0]\n",
    "        self.n_features=self.X.shape[1]\n",
    "        self.W=np.random.random(self.n_features)-0.5\n",
    "        self.C=C\n",
    "        self.learning_rate=learning_rate\n",
    "        self.n_iter=n_iter\n",
    "        \n",
    "    def loss_func(self):\n",
    "        hinge_loss = np.maximum(0,1-self.y*np.dot(self.X,self.W))\n",
    "        slack_term = hinge_loss.mean()*self.C\n",
    "        w = self.W[:-1]\n",
    "        cost_f = 0.5*np.sum(w**2)\n",
    "        return cost_f + slack_term\n",
    "\n",
    "    def d_obj_func(self):\n",
    "        I=np.where(self.y*np.dot(self.X,self.W)>=1, 0, -1)[:,None]\n",
    "        dJ=np.zeros(self.W.shape)\n",
    "        dJ[:-1]=(I*self.X[:,:-1]*(np.array(self.y)[:,np.newaxis])).mean(axis=0)*self.C+self.W[:-1] \n",
    "        dJ[-1]=(I*self.C*(np.array(self.y)[:,np.newaxis])).mean(axis=0)                     \n",
    "        return dJ\n",
    "\n",
    "    def train(self):\n",
    "        loss=[]\n",
    "        for iter_ in range(self.n_iter):\n",
    "            dJ=self.d_obj_func()\n",
    "            self.W = self.W - self.learning_rate*dJ\n",
    "            loss_per_iter = self.loss_func()\n",
    "            loss.append(loss_per_iter)\n",
    "            if iter_%10000 == 0:\n",
    "                print('dj:', dJ)\n",
    "                print('W =', self.W)\n",
    "                print('loss at iter {}:'.format(iter_), loss_per_iter)\n",
    "        self.losses=loss\n",
    "\n",
    "\n",
    "    def predict(self,x):\n",
    "        # augmented matrix X = [w, b]\n",
    "        x = np.hstack([x,np.ones([x.shape[0],1])])\n",
    "        y_preds=[]\n",
    "        for i in x:\n",
    "            y_pred=1 if np.sign(i.dot(self.W))>=0 else -1\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softsvm_gd = SoftMarginSVM(X,labels)\n",
    "softsvm_gd.train()\n",
    "\n",
    "svm_sklearn=SVC(C=3,kernel='linear')\n",
    "svm_sklearn.fit(X,labels)\n",
    "\n",
    "print('not sklearn svm weights:', softsvm_gd.W)\n",
    "print('sklearn svm weights:', svm_sklearn.coef_, \n",
    "      'sklearn svm weights:', svm_sklearn.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result\n",
    "plot_contour(x=X[:, 0],\n",
    "             y=X[:, 1],\n",
    "             labels=labels,\n",
    "             models=(\n",
    "                     softsvm_gd,\n",
    "                     svm_sklearn\n",
    "                    ),\n",
    "             row=1,\n",
    "             col=2,\n",
    "             figsize=FIGSIZE,\n",
    "             cmap1=plt.cm.coolwarm, \n",
    "             cmap2=plt.cm.coolwarm,\n",
    "             titles=(\n",
    "                    'soft margin svm (not sklearn)',\n",
    "                     'svm sklearn'\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
